#!/bin/python3
import os
import argparse
import time
import datetime
import subprocess


def current_milli_time(): return int(round(time.time() * 1000))


def main():
  parser = argparse.ArgumentParser()
  parser.add_argument("--linux-username", help="The linux username, eg, yshen")
  parser.add_argument("--hadoop-username", help="The hadoop user name, eg, bigdata17")
  parser.add_argument("--task-no", help="The task number, 1 = all words, 2 = words' length > 6")
  parser.add_argument("--output-file", '-o', help="The output file on linux")
  parser.add_argument("--input-file", "-f", help="The input file name in hdfs")
  parser.add_argument("--debug-file", '-d', help="The debug file on linux")
  parser.add_argument("--filter-word", action="store_true", help="Filter out words whose length is less than 6")
  parser.add_argument("--phase-1-mapper", help="Number of mappers in phase 1")
  parser.add_argument("--phase-2-mapper", help="Number of mappers in phase 2")
  parser.add_argument("--phase-1-reducer", help="Number of reducers in phase 1")
  parser.add_argument("--phase-2-reducer", help="Number of reducers in phase 2")


  args = parser.parse_args()

  linux_username = args.linux_username
  hadoop_username = args.hadoop_username
  filter_word = args.filter_word
  output_file = args.output_file
  input_file = args.input_file
  debug_file = args.debug_file
  phase_1_mapper = int(args.phase_1_mapper) if args.phase_1_mapper else None
  phase_1_reducer = int(args.phase_1_reducer) if args.phase_1_reducer else None
  phase_2_mapper = int(args.phase_2_mapper) if args.phase_2_mapper else None
  phase_2_reducer = int(args.phase_2_reducer) if args.phase_2_reducer else None


  # do cleanup
  print('performing cleanup job....')
  cleanup_command = 'HADOOP_USER_NAME={} hadoop fs -rm -r -f /user/{}/phase*'.format(hadoop_username, hadoop_username)
  os.system(cleanup_command)
  print('cleanup done')


  phase_1_command = 'HADOOP_USER_NAME={hadoop_username} hadoop jar $HADOOP_HOME/share/hadoop/tools/lib/hadoop-*streaming*.jar {num_phase_1_mapper} {num_phase_1_reducer} -file /home/{linux_username}/count_words_map_reduce/{mapper_file} -mapper /home/{linux_username}/count_words_map_reduce/{mapper_file} -file /home/{linux_username}/count_words_map_reduce/word_count_reducer.py  -reducer /home/{linux_username}/count_words_map_reduce/word_count_reducer.py -input /user/{hadoop_username}/{input_file} -output /user/{hadoop_username}/phase-1-output > {debug_file}'.format(
    linux_username=linux_username,
    hadoop_username=hadoop_username, 
    debug_file=debug_file, 
    input_file=input_file,
    mapper_file='word_count_mapper.py' if not filter_word else 'word_count_mapper_non_trivial.py',
    num_phase_1_mapper=' -D mapreduce.job.maps={phase_1_mapper} '.format(phase_1_mapper=str(phase_1_mapper)) if phase_1_mapper else '',
    num_phase_1_reducer=' -D mapreduce.job.reduces={phase_1_reducer} '.format(phase_1_reducer=str(phase_1_reducer)) if phase_1_reducer else '',
  )

  print('phase_1_command:{}'.format(phase_1_command))
  print('performing phase 1: word counting')
  phase_1_start_timestamp = current_milli_time()
  with open('/home/{linux_username}/count_words_map_reduce/{debug_file}'.format(linux_username=linux_username, debug_file=debug_file), 'w') as f:
    subprocess.run(phase_1_command, shell=True, stdout=f)
  phase_1_complete_timestamp = current_milli_time()
  print('word counting done, taking {} milliseconds'.format(str(phase_1_complete_timestamp - phase_1_start_timestamp)))


  phase_2_command = 'HADOOP_USER_NAME={hadoop_username} hadoop jar $HADOOP_HOME/share/hadoop/tools/lib/hadoop-*streaming*.jar {num_phase_2_mapper} {num_phase_2_reducer} -D mapred.output.key.comparator.class=org.apache.hadoop.mapred.lib.KeyFieldBasedComparator -D  mapred.text.key.comparator.options=-n -file /home/{linux_username}/count_words_map_reduce/word_sort_mapper.py    -mapper /home/{linux_username}/count_words_map_reduce/word_sort_mapper.py -file /home/{linux_username}/count_words_map_reduce/word_sort_reducer.py    -reducer /home/{linux_username}/count_words_map_reduce/word_sort_reducer.py  -input /user/{hadoop_username}/phase-1-output/* -output /user/{hadoop_username}/phase-2-output > {debug_file}'.format(
    linux_username=linux_username, 
    hadoop_username=hadoop_username,
    debug_file=debug_file,
    num_phase_2_mapper=' -D mapreduce.job.maps={phase_2_mapper} '.format(phase_2_mapper=str(phase_2_mapper)) if phase_2_mapper else '',
    num_phase_2_reducer=' -D mapreduce.job.reduces={phase_2_reducer} '.format(phase_2_reducer=str(phase_2_reducer)) if phase_2_reducer else '',
  )

  print('performing phase 2: word sorting')
  phase_2_start_timestamp = current_milli_time()
  #os.system(phase_2_command)
  with open('/home/{linux_username}/count_words_map_reduce/{debug_file}'.format(linux_username=linux_username, debug_file=debug_file), 'a') as f:
    subprocess.run(phase_2_command, shell=True, stdout=f)
  phase_2_complete_timestamp = current_milli_time()
  print('word sorting done, taking {} milliseconds'.format(str(phase_2_complete_timestamp - phase_2_complete_timestamp)))

  # Start sorting
  sorting_command = 'HADOOP_USER_NAME={hadoop_username} hadoop fs -cat /user/{hadoop_username}/phase-2-output/part* | sort -n -k1 -r | head -n100'.format(hadoop_username=hadoop_username)

  output_file = '/home/{linux_username}/count_words_map_reduce/{output_file}'.format(linux_username=linux_username, output_file=output_file)

  with open(output_file, 'w') as f:
    subprocess.run(sorting_command, shell=True, stdout=f)
    res = """
  Number of phase1 mappers: {phase_1_mapper}
  Number of phase2 mappers: {phase_2_mapper}
  Number of phase1 reducers: {phase_1_reducer}
  Number of phase2 reducers: {phase_2_reducer}
  phase 1 word count took: {phase_1_timespan} milliseconds.
  phase 2 word sort took: {phase_2_timespan} milliseconds,
  """.format(
      phase_1_mapper=str(phase_1_mapper),
      phase_2_mapper=str(phase_2_mapper),
      phase_1_timespan=str(phase_1_complete_timestamp - phase_1_start_timestamp),
      phase_2_timespan=str(phase_2_complete_timestamp - phase_2_start_timestamp),
      phase_1_reducer=str(phase_1_reducer),
      phase_2_reducer=str(phase_2_reducer),
    )
    f.write(res)
    f.write('==========================\n')
     

if __name__ == "__main__":
    main()